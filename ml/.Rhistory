est_method = "1par")
test_result <- ci_test(lg_object = lg_object, n_rep = n_rep)
test_result
test_result$p_value
test_result$observed
test_result$replicated
order
order <- 3
test_result <- ci_test(lg_object = lg_object, n_rep = n_rep)
test_result$p_value
test_result$replicated
test_result$observed
acf(ts)
pacf(ts)
data(dmbp)
.TS <- dmbp <- dmbp[, "V1"]
fit <-  garchFit(~ garch(1,1), data = dmbp, trace = FALSE)
# GARCH-filtrate the time series
library(fGarch)
fit <-  garchFit(~ garch(1,1), data = dmbp, trace = FALSE)
fit
str(fit)
fit@residuals
plot(fit@residuals, type = "l")
dmbp_garchres <- fit@residuals
dmbp_garchres <- tibble(X = fit@residuals)
dmbp <- tibble(raw = dmbp,
garch_res = fit@residuals)
lg_object <- lg_main(dmbp)
lg_object$transformed_data
tibble(lg_object$transformed_data)
tibble(lg_object$transformed_data)
transformed <- tibble(lg_object$transformed_data)
colnames(transformed) <- c("raw_trans", "garch_res_trans")
dmbp <- bind_cols(dmbp, transformed)
dmbp
transformed <- tibble(lg_object$transformed_data)
colnames(transformed)
transformed <- data.frame(lg_object$transformed_data)
transformed
colnames(transformed) <- c("raw_trans", "garch_res_trans")
dmbp <- tibble(raw = dmbp,
garch_res = fit@residuals)
lg_object <- lg_main(dmbp)
transformed <- data.frame(lg_object$transformed_data)
colnames(transformed) <- c("raw_trans", "garch_res_trans")
dmbp <- bind_cols(dmbp, transformed)
dmbp
data(dmbp)
.TS <- dmbp <- dmbp[, "V1"]
# GARCH-filtrate the time series
library(fGarch)
fit <-  garchFit(~ garch(1,1), data = dmbp, trace = FALSE)
dmbp_all <- tibble(raw = dmbp,
garch_res = fit@residuals)
lg_object <- lg_main(dmbp_all)
transformed <- data.frame(lg_object$transformed_data)
colnames(transformed) <- c("raw_trans", "garch_res_trans")
head(transformed)
dmbp_all <- bind_cols(dmbp_all, transformed)
dmbp_all
transformed
plot(transformed)
dmbp_all
dmbp_all <- tibble(raw = dmbp,
garch_res = fit@residuals)
dmbp_all
lg_object <- lg_main(dmbp_all)
lg_object$transformed_data
dmbp
# GARCH-filtrate the time series
library(ruarch)
# GARCH-filtrate the time series
library(rugarch)
garch_spec <- ugarchspec(variance.model = list(garchOrder = c(1,1)),
mean.model = list(armaOrder=c(0,0),include.mean = FALSE),
distribution.model = "std")
garch_fit <-  ugarchfit(spec = garch_spec, data = dmbp,
solver.control=list(trace = 1))
garch_fit
str(garch_fit)
garch_fit@fit@residuals
garch_fit$fit
garch_fit@fit
garch_fit@fit$residuals
dmbp_all <- tibble(raw = dmbp,
garch_res = garch_fit@fit$residuals)
dmbp_all
garch_fit@fit$fitted.values
garch_fit@fit
scatter
library(dplyr)
library(ggplot2)
library(tidymodels)      # <- This is new. Tidyverse take on modeling
no_color <- "#00000020"
yes_color <- "#FF000070"
pred_color <- c("#FFFFFF00", "#AA3333DD")
cutoff <- .5
grid_resolution <- 50
# Read the data
telco <-
readr::read_csv("telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv") %>%
select(Churn, MonthlyCharges, tenure) %>%
mutate(Churn = as.factor(Churn))
# Make a basic scatterplot
scatter <-
telco %>%
ggplot(aes(x = MonthlyCharges, y = tenure, colour = Churn)) +
geom_point() +
xlab("Monthly charges ($)") +
ylab("Tenure (months)") +
scale_color_manual(values=c(no_color, yes_color)) +
theme_classic()
scatter
setwd("~/repos/ban400-lectures/ml")
library(dplyr)
library(ggplot2)
library(tidymodels)      # <- This is new. Tidyverse take on modeling
no_color <- "#00000020"
yes_color <- "#FF000070"
pred_color <- c("#FFFFFF00", "#AA3333DD")
cutoff <- .5
grid_resolution <- 50
# Read the data
telco <-
readr::read_csv("telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv") %>%
select(Churn, MonthlyCharges, tenure) %>%
mutate(Churn = as.factor(Churn))
# Make a basic scatterplot
scatter <-
telco %>%
ggplot(aes(x = MonthlyCharges, y = tenure, colour = Churn)) +
geom_point() +
xlab("Monthly charges ($)") +
ylab("Tenure (months)") +
scale_color_manual(values=c(no_color, yes_color)) +
theme_classic()
scatter
ggsave("~/scatter.jpg")
library(dplyr)
library(ggplot2)
library(tidymodels)      # <- This is new. Tidyverse take on modeling
no_color <- "#00000020"
yes_color <- "#FF000070"
pred_color <- c("#FFFFFF00", "#AA3333DD")
cutoff <- .5
grid_resolution <- 50
readr::read_csv("telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv") %>%
select(Churn, MonthlyCharges, tenure)
readr::read_csv("telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv") %>%
select(Churn, MonthlyCharges, tenure) %>%
mutate(Churn = as.factor(Churn))
telco <-
readr::read_csv("telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv") %>%
select(Churn, MonthlyCharges, tenure) %>%
mutate(Churn = as.factor(Churn))
telco %>%
ggplot(aes(x = MonthlyCharges, y = tenure, colour = Churn))
telco %>%
ggplot(aes(x = MonthlyCharges, y = tenure, colour = Churn)) +
geom_point()
telco %>%
ggplot(aes(x = MonthlyCharges, y = tenure, colour = Churn)) +
geom_point() +
xlab("Monthly charges ($)") +
ylab("Tenure (months)") +
scale_color_manual(values=c(no_color, yes_color)) +
theme_classic()
# Make a basic scatterplot
scatter <-
telco %>%
ggplot(aes(x = MonthlyCharges, y = tenure, colour = Churn)) +
geom_point() +
xlab("Monthly charges ($)") +
ylab("Tenure (months)") +
scale_color_manual(values=c(no_color, yes_color)) +
theme_classic()
scatter
# Fit a logistic regression to the data using tidymodels
fitted_logistic <-
logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification") %>%
fit(Churn ~ ., data = telco)
# Look at the results
tidy(fitted_logistic)
# Draw the decision boundary for logistic regression:
newdata <-
expand.grid(MonthlyCharges = seq(from = 20,
to = 120,
length.out = grid_resolution),
tenure = seq(from = 0,
to = 80,
length.out = grid_resolution))
predictions <-
newdata %>%
bind_cols(pred_prob_logistic = predict(fitted_logistic,
new_data = newdata,
type = "prob")$.pred_Yes)
scatter +
geom_contour_filled(aes(x = MonthlyCharges,
y = tenure,
z = pred_prob_logistic),
data = predictions,
inherit.aes = FALSE,
breaks = c(0, 0.5, 1)) +
scale_fill_manual(values = pred_color,
name="Predicted probability",
drop = FALSE) +
geom_contour(aes(x = MonthlyCharges,
y = tenure,
z = pred_prob_logistic),
data = predictions,
inherit.aes = FALSE,
breaks = c(0, 0.5, 1),
colour = "black",
size = 1.5)
install.packages("kknn")
# Do a prediction using k-nearest-neighbours (kNN)
# Requires package: "kknn"
fitted_knn <-
nearest_neighbor(neighbors = 50) %>%
set_engine("kknn") %>%
set_mode("classification") %>%
fit(Churn ~ ., data = telco)
predictions <-
predictions %>%
mutate(pred_prob_knn = predict(fitted_knn,
new_data = newdata,
type = "prob")$.pred_Yes)
scatter +
geom_contour_filled(aes(x = MonthlyCharges,
y = tenure,
z = pred_prob_knn),
data = predictions,
inherit.aes = FALSE,
breaks = c(0, 0.5, 1)) +
scale_fill_manual(values = pred_color,
name="Predicted probability",
drop = FALSE) +
geom_contour(aes(x = MonthlyCharges,
y = tenure,
z = pred_prob_knn),
data = predictions,
inherit.aes = FALSE,
breaks = c(0, 0.5, 1),
colour = "black",
size = 1.5)
# Split the data into training and testing set
set.seed(1)
?initial_split()
# Specify the recipe
knn_recipe <-
recipe(Churn ~ ., data = telco)
# Set up the workflow
knn_workflow <-
workflow() %>%
add_model(knn_mod) %>%
add_recipe(knn_recipe)
# Specify the model
knn_mod <-
nearest_neighbor(neighbors = tune()) %>%
set_mode("classification") %>%
set_engine("kknn")
# Specify the recipe
knn_recipe <-
recipe(Churn ~ ., data = telco)
# Set up the workflow
knn_workflow <-
workflow() %>%
add_model(knn_mod) %>%
add_recipe(knn_recipe)
# Make a search grid for the k-parameter
knn_grid <- grid_latin_hypercube(
neighbors(c(3, round(nrow(telco)/5))),
size = 15
)
# Calculate the cross-validated AUC for all the k's in the grid
knn_tune_result <-
tune_grid(
knn_workflow,
resamples = telco_folds,
grid = knn_grid
)
telco_folds <- vfold_cv(telco_train, strata = Churn)
# Split the data into training and testing set
set.seed(1)
telco_split <- initial_split(telco, strata = Churn)
telco_train <- training(telco_split)
telco_test  <- testing (telco_split)
telco_folds <- vfold_cv(telco_train, strata = Churn)
# Specify the model
knn_mod <-
nearest_neighbor(neighbors = tune()) %>%
set_mode("classification") %>%
set_engine("kknn")
# Specify the recipe
knn_recipe <-
recipe(Churn ~ ., data = telco)
# Set up the workflow
knn_workflow <-
workflow() %>%
add_model(knn_mod) %>%
add_recipe(knn_recipe)
# Make a search grid for the k-parameter
knn_grid <- grid_latin_hypercube(
neighbors(c(3, round(nrow(telco)/5))),
size = 15
)
# Calculate the cross-validated AUC for all the k's in the grid
knn_tune_result <-
tune_grid(
knn_workflow,
resamples = telco_folds,
grid = knn_grid
)
knn_tune_result
??auc
knn_tune_result %>% roc_auc()
??metric_set
??metric
knn_tune_result %>% collect_metrics()
knn_tune_result %>% collect_metrics() %>% filter(.metric = "roc_auc")
knn_tune_result %>% collect_metrics() %>% filter(.metric == "roc_auc")
# Which k is the best?
knn_tune_result %>%
select_best(metric = "roc_auc")
# Put the best k in the workflow
knn_tuned <-
finalize_workflow(
knn_workflow,
parameters = knn_tune_result %>% select_best(metric = "roc_auc")
)
# Fit the model
fitted_knn <-
knn_tuned %>%
fit(data = telco_train)
# Predict the test data
predictions_testing <-
fitted_knn %>%
predict(new_data = telco_test,
type = "prob") %>%
mutate(truth = telco_test$Churn)
# Calculate the AUC
predictions_testing %>%
roc_auc(truth, .pred_No)
truth
?roc_auc
predictions_testing <-
fitted_knn %>%
predict(new_data = telco_test,
type = "prob") %>%
mutate(truth = telco_test$Churn)
fitted_knn %>%
predict(new_data = telco_test,
type = "prob")
scatter +
geom_contour_filled(aes(x = MonthlyCharges,
y = tenure,
z = pred_prob_knn),
data = predictions,
inherit.aes = FALSE,
breaks = c(0, 0.5, 1)) +
scale_fill_manual(values = pred_color,
name="Predicted probability",
drop = FALSE) +
geom_contour(aes(x = MonthlyCharges,
y = tenure,
z = pred_prob_knn),
data = predictions,
inherit.aes = FALSE,
breaks = c(0, 0.5, 1),
colour = "black",
size = 1.5)
# Read data ------
names <-
read_csv("spambase/spambase.names",
skip = 32,
col_names = FALSE) %>%
separate(X1,
into = c("name", "drop"),
sep = ":") %>%
select(-drop) %>%
bind_rows(tibble(name = "spam")) %>%
pull
library(readr)
library(dplyr)
library(tidymodels)
library(rpart)           # For decision trees
library(rpart.plot)      # Separate package for plotting trees
# Read data ------
names <-
read_csv("spambase/spambase.names",
skip = 32,
col_names = FALSE) %>%
separate(X1,
into = c("name", "drop"),
sep = ":") %>%
select(-drop) %>%
bind_rows(tibble(name = "spam")) %>%
pull
spam <-
read_csv("spambase/spambase.data", col_names = names) %>%
mutate(spam = as.factor(spam))
# What is the distribution of spam e-mail in the data set?
spam %>%
group_by(spam) %>%
summarize(n_emails = n()) %>%
mutate(share = n_emails/sum(n_emails))
# Split the data into training and test data, and divide the training data into
# folds for cross-validaton.
set.seed(1)
spam_split <- initial_split(spam, strata = spam)
spam_train <- training(spam_split)
spam_test  <- testing (spam_split)
spam_folds <- vfold_cv(spam_train, strata = spam, v = 3)  # v = 5 or 10 is more common
# Specify the recipe, that is common for all models
spam_recipe <-
recipe(spam ~ ., data = spam)
# Specify the decistion tree
tree_mod <-
decision_tree(
tree_depth = tune(),
min_n = tune()) %>%
set_mode("classification") %>%
set_engine("rpart")
# Set up the workflow
tree_workflow <-
workflow() %>%
add_model(tree_mod) %>%
add_recipe(spam_recipe)
# Make a search grid for the k-parameter
tree_grid <-
grid_latin_hypercube(
tree_depth(),
min_n(),
size = 10
)
tree_grid
plot(tree_grid)
# Calculate the cross-validated AUC for all the k's in the grid
tree_tune_result <-
tune_grid(
tree_workflow,
resamples = spam_folds,
grid = tree_grid,
control = control_grid(save_pred = TRUE)
)
# Which parameter combination is the best?
tree_tune_result %>%
select_best(metric = "roc_auc")
# Put the best parameters in the workflow
tree_tuned <-
finalize_workflow(
tree_workflow,
parameters = tree_tune_result %>% select_best(metric = "roc_auc")
)
# Fit the model
fitted_tree <-
tree_tuned %>%
fit(data = spam_train)
# Plot the model
rpart.plot(fitted_tree$fit$fit$fit)
# Predict the train and test data
predictions_tree_test <-
fitted_tree %>%
predict(new_data = spam_test,
type = "prob") %>%
mutate(truth = spam_test$spam)
predictions_tree_train <-
fitted_tree %>%
predict(new_data = spam_train,
type = "prob") %>%
mutate(truth = spam_train$spam)
# Calculate the AUC
auc_tree <-
predictions_tree_test %>%
roc_auc(truth, .pred_0) %>%
mutate(where = "test") %>%
bind_rows(predictions_tree_train %>%
roc_auc(truth, .pred_0) %>%
mutate(where = "train")) %>%
mutate(model = "decision_tree")
auc_tree
predictions_tree_test <-
fitted_tree %>%
predict(new_data = spam_test,
type = "prob")
fitted_tree %>%
predict(new_data = spam_test,
type = "prob")
# Predict the train and test data
predictions_tree_test <-
fitted_tree %>%
predict(new_data = spam_test,
type = "prob") %>%
mutate(truth = spam_test$spam)
predictions_tree_test %>%
roc_auc(truth, .pred_0)
predictions_tree_test %>%
roc_auc(truth, .pred_0) %>%
mutate(where = "test")
# Calculate the AUC
auc_tree <-
predictions_tree_test %>%
roc_auc(truth, .pred_0) %>%
mutate(where = "test") %>%
bind_rows(predictions_tree_train %>%
roc_auc(truth, .pred_0) %>%
mutate(where = "train")) %>%
mutate(model = "decision_tree")
auc_tree
